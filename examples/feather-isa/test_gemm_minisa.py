#!/usr/bin/env python3
# Copyright Allo authors. All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0

"""
Test GEMM using MINISA (Minimal Instruction Set Architecture) for FEATHER+.

This test demonstrates how to program FEATHER+ at Virtual Neuron (VN) granularity
using the 4 MINISA instructions:
1. SetIVNLayout - Configure input VN layout
2. SetWVNLayout - Configure weight VN layout
3. SetOVNLayout - Configure output VN layout
4. SetMapping - Execute compute tile

Example from paper: Matrix multiplication C = A @ B
where A: (M, K), B: (K, N), C: (M, N)
"""

import sys
import os
import argparse
import numpy as np

# Add parent directory to path to import feather_isa
sys.path.insert(0, os.path.dirname(__file__))

from feather_isa import (
    FEATHER_ISA,
    create_minisa_program_gemm,
    print_minisa_program,
    SetIVNLayout,
    SetWVNLayout,
    SetOVNLayout,
    SetMapping,
)

import allo
from allo.ir.types import int8, int32


def test_gemm_minisa(M: int, N: int, K: int, AH: int, AW: int, verbose: bool = True):
    """
    Test matrix multiplication using MINISA programming model.

    Args:
        M: Number of rows in A (and C)
        N: Number of columns in B (and C)
        K: Number of columns in A (and rows in B)
        AH: PE array height (VN size)
        AW: PE array width
        verbose: Print detailed information
    """
    print("=" * 80)
    print(f"FEATHER-ISA GEMM Test")
    print("=" * 80)
    print(f"Matrix dimensions: M={M}, N={N}, K={K}")
    print(f"PE array configuration: AH={AH}, AW={AW}")
    print(f"Virtual Neuron (VN) size: {AH} elements")
    print("-" * 80)

    # Create random input matrices
    np.random.seed(42)
    A = np.random.randint(-4, 4, size=(M, K)).astype(np.int8)
    B = np.random.randint(-4, 4, size=(K, N)).astype(np.int8)
    C_expected = (A.astype(np.int32) @ B.astype(np.int32)).astype(np.int8)

    if verbose:
        print(f"Input A shape: {A.shape}")
        print(f"Input B shape: {B.shape}")
        print(f"Expected output C shape: {C_expected.shape}")
        print("-" * 80)

    # Create MINISA program
    ivn_layout, wvn_layout, ovn_layout, mappings = create_minisa_program_gemm(
        M, N, K, AH, AW
    )

    if verbose:
        print_minisa_program(ivn_layout, wvn_layout, ovn_layout, mappings)

    # Initialize FEATHER-ISA accelerator
    feather = FEATHER_ISA(AH, AW, dtype=int8)

    # Execute MINISA program
    print("Executing MINISA program...")
    print("-" * 80)

    # Step 1: Configure layouts
    feather.set_ivn_layout(ivn_layout)
    feather.set_wvn_layout(wvn_layout)
    feather.set_ovn_layout(ovn_layout)

    # Step 2: Execute mapping(s)
    print(f"Executing {len(mappings)} SetMapping instruction(s)...")
    C_actual = feather.execute_mapping(mappings[0], A, B)

    print("-" * 80)

    # Verify results
    print("Verifying results...")
    try:
        np.testing.assert_array_equal(C_actual, C_expected)
        print("‚úÖ TEST PASSED! Output matches expected result.")

        # Additional verification
        max_diff = np.max(np.abs(C_actual.astype(np.int32) - C_expected.astype(np.int32)))
        print(f"   Maximum difference: {max_diff}")

        if verbose:
            print(f"\nSample output values:")
            print(f"   C_actual[0, :5] = {C_actual[0, :5]}")
            print(f"   C_expected[0, :5] = {C_expected[0, :5]}")

        return True

    except AssertionError as e:
        print("‚ùå TEST FAILED! Output does not match expected result.")
        print(f"   Error: {e}")

        # Detailed failure analysis
        diff = C_actual.astype(np.int32) - C_expected.astype(np.int32)
        max_diff = np.max(np.abs(diff))
        mean_diff = np.mean(np.abs(diff))

        print(f"   Maximum difference: {max_diff}")
        print(f"   Mean absolute difference: {mean_diff:.2f}")

        if verbose:
            print(f"\nFirst mismatch location:")
            mismatch = np.where(C_actual != C_expected)
            if len(mismatch[0]) > 0:
                i, j = mismatch[0][0], mismatch[1][0]
                print(f"   Position ({i}, {j}): actual={C_actual[i, j]}, expected={C_expected[i, j]}")

        return False


def test_gemm_allo_kernel(AH: int, AW: int, verbose: bool = True):
    """
    Test GEMM using Allo kernel with VN-level computation.
    This demonstrates how VN-level operations can be expressed in Allo.
    NOTE: This test requires LLVM backend to be set up (LLVM_BUILD_DIR environment variable).
    """
    print("\n" + "=" * 80)
    print(f"FEATHER-ISA Allo Kernel Test (VN-level) [OPTIONAL]")
    print("=" * 80)
    print(f"PE array configuration: AH={AH}, AW={AW}")
    print("-" * 80)

    # Check if LLVM is available
    if os.getenv("LLVM_BUILD_DIR") is None:
        print("‚ö†Ô∏è  LLVM_BUILD_DIR not set - skipping Allo kernel test")
        print("   To run this test, set LLVM_BUILD_DIR environment variable")
        print("   This test is optional - MINISA functional model is the main test")
        return True  # Return True to not fail the overall test suite

    Ty = int8

    # Define VN-level GEMM kernel
    def gemm_vn_tile(A: Ty[AH, AW], B: Ty[AH, AW, AH], C: Ty[AH, AW]):
        """
        VN-level GEMM tile computation.
        Each PE computes an AH-way dot product (one Virtual Neuron).

        A: Input VNs - each column feeds one PE column
        B: Weight VNs - B[i,j,k] is weight for PE(i,j) at position k
        C: Output VNs - accumulated partial sums
        """
        for i in range(AH):  # PE rows
            for j in range(AW):  # PE columns
                temp: Ty = 0
                for k in range(AH):  # AH-way dot product (VN)
                    temp += A[k, j] * B[i, j, k]
                C[i, j] += temp  # Accumulate to output

    # Build with LLVM backend
    print("Building Allo kernel for LLVM...")
    s = allo.customize(gemm_vn_tile)
    mod = s.build(target="llvm")
    print("‚úÖ Allo kernel built successfully for LLVM backend")

    # Test with random data
    np.random.seed(42)
    A = np.random.randint(-4, 4, size=(AH, AW)).astype(np.int8)
    B = np.random.randint(-4, 4, size=(AH, AW, AH)).astype(np.int8)
    C = np.zeros((AH, AW), dtype=np.int8)

    # Run kernel
    print("Executing VN-level GEMM tile...")
    mod(A, B, C)

    # Compute reference
    C_ref = np.zeros((AH, AW), dtype=np.int8)
    for i in range(AH):
        for j in range(AW):
            for k in range(AH):
                C_ref[i, j] += A[k, j] * B[i, j, k]

    # Verify
    try:
        np.testing.assert_array_equal(C, C_ref)
        print("‚úÖ VN-level kernel test PASSED!")

        if verbose:
            print(f"   Output sample C[0, :] = {C[0, :]}")

        return True
    except AssertionError:
        print("‚ùå VN-level kernel test FAILED!")
        print(f"   Max diff: {np.max(np.abs(C.astype(np.int32) - C_ref.astype(np.int32)))}")
        return False


def main():
    parser = argparse.ArgumentParser(
        description="Test GEMM with MINISA programming model for FEATHER+"
    )
    parser.add_argument("--M", type=int, default=8, help="Number of rows in A (must be multiple of AH)")
    parser.add_argument("--N", type=int, default=8, help="Number of columns in B (must be multiple of AH)")
    parser.add_argument("--K", type=int, default=8, help="Inner dimension (must be multiple of AH)")
    parser.add_argument("--AH", type=int, default=4, help="PE array height (VN size)")
    parser.add_argument("--AW", type=int, default=4, help="PE array width")
    parser.add_argument("--verbose", action="store_true", help="Print detailed information")

    args = parser.parse_args()

    # Validate dimensions
    if args.M % args.AH != 0:
        print(f"Error: M={args.M} must be divisible by AH={args.AH}")
        sys.exit(1)
    if args.N % args.AH != 0:
        print(f"Error: N={args.N} must be divisible by AH={args.AH}")
        sys.exit(1)
    if args.K % args.AH != 0:
        print(f"Error: K={args.K} must be divisible by AH={args.AH}")
        sys.exit(1)

    # Run tests
    all_passed = True

    # Test 1: MINISA functional model
    test1_passed = test_gemm_minisa(
        args.M, args.N, args.K, args.AH, args.AW, args.verbose
    )
    all_passed = all_passed and test1_passed

    # Test 2: Allo VN-level kernel
    test2_passed = test_gemm_allo_kernel(args.AH, args.AW, args.verbose)
    all_passed = all_passed and test2_passed

    # Final summary
    print("\n" + "=" * 80)
    print("FINAL TEST SUMMARY")
    print("=" * 80)
    print(f"1. MINISA Functional Model: {'‚úÖ PASSED' if test1_passed else '‚ùå FAILED'}")
    print(f"2. Allo VN-level Kernel:    {'‚úÖ PASSED' if test2_passed else '‚ùå FAILED'}")
    print("-" * 80)
    if all_passed:
        print("üéâ ALL TESTS PASSED!")
    else:
        print("‚ö†Ô∏è  SOME TESTS FAILED")
    print("=" * 80)

    return 0 if all_passed else 1


if __name__ == "__main__":
    sys.exit(main())
